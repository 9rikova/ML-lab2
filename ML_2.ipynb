{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "annoying-details",
   "metadata": {},
   "source": [
    "# Машинное обучение. Лабораторная работа №2.\n",
    "Выполнила: *Девятерикова Александра Владимировна*  \n",
    "Группа: *М8О-301Б-18*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ordinary-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "peaceful-teaching",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('winequality-red.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-reconstruction",
   "metadata": {},
   "source": [
    "## Настройка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "equipped-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix, target = data.drop(columns=['quality']).to_numpy(dtype=np.float128), np.array(data['quality'], \n",
    "                                                                                             dtype=np.float128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-metabolism",
   "metadata": {},
   "source": [
    "Разделим входные данные на два класса:  \n",
    "Первый класс $-$ качество вина более 5  \n",
    "Второй класс $-$ качество вина не более 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "molecular-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.47091932457786\n",
      "46.52908067542214\n"
     ]
    }
   ],
   "source": [
    "print(data[data['quality'] > 5].shape[0] / data['quality'].shape[0] * 100)\n",
    "print(data[data['quality'] <= 5].shape[0] / data['quality'].shape[0] * 100)\n",
    "\n",
    "for index in range(len(target)):\n",
    "    if target[index] > 5:\n",
    "        target[index] = 1\n",
    "    else:\n",
    "        target[index] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-likelihood",
   "metadata": {},
   "source": [
    "Отнормируем входные признаки и разделим датасет на обучающую и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "renewable-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_signs = design_matrix.shape[1]\n",
    "max_values = np.zeros(cnt_signs)\n",
    "for i in range(cnt_signs):\n",
    "    max_in_clmn = design_matrix[:, i].max()\n",
    "    max_values[i] = max_in_clmn\n",
    "    design_matrix[:, i] /= max_in_clmn\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(design_matrix, target, \n",
    "                                                                            test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-storm",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "handled-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression:\n",
    "    \n",
    "    def __init__(self, step=1e-1, n_iter=10000):\n",
    "        self.step = step\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "        \n",
    "    def logistic_function(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        x = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        self._weights = np.zeros(x.shape[1])\n",
    "        for i in range(self.n_iter):\n",
    "            z = np.dot(x, self._weights)\n",
    "            gradient = np.dot(x.T, self.logistic_function(z) - Y) / Y.size\n",
    "            self._weights -= self.step * gradient\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        x = np.array([X])\n",
    "        x = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "        return self.logistic_function(np.dot(x, self._weights)).round()\n",
    "    \n",
    "    \n",
    "    def score(self, X, Y):\n",
    "        right_predict_number = 0\n",
    "        for i in range(Y.shape[0]):\n",
    "            if self.predict(X[i]) == Y[i]:\n",
    "                right_predict_number += 1\n",
    "\n",
    "        return right_predict_number / Y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-survivor",
   "metadata": {},
   "source": [
    "### Проверка точности и сравнение с реализацией sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "isolated-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlg = MyLogisticRegression()\n",
    "mlg.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "quantitative-insulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат собственной реализации логистической регресси на обучающей выборке: 74.90226739640345%\n",
      "Результат собственной реализации логистической регрессии на тестовой выборке: 72.1875%\n"
     ]
    }
   ],
   "source": [
    "print('Результат собственной реализации логистической регресси на обучающей выборке: {}%'\n",
    "      .format(mlg.score(features_train, target_train) * 100))\n",
    "print('Результат собственной реализации логистической регрессии на тестовой выборке: {}%'\n",
    "      .format(mlg.score(features_test, target_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "textile-component",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklg = LogisticRegression()\n",
    "sklg.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "organizational-fever",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат sklearn реализации логистической регрессии: 72.1875%\n"
     ]
    }
   ],
   "source": [
    "print('Результат sklearn реализации логистической регрессии: {}%'\n",
    "      .format(sklg.score(features_test, target_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-syndrome",
   "metadata": {},
   "source": [
    "##  Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dirty-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    class Node:\n",
    "        def __init__(self, isLeaf=False, feature_index=None, split_value=None, sons=None, value=None):\n",
    "            self.isLeaf = isLeaf\n",
    "            if not isLeaf:\n",
    "                self.feature_index = feature_index\n",
    "                self.split_value = split_value\n",
    "                self.sons = sons\n",
    "                self.left = None\n",
    "                self.right = None\n",
    "            else:\n",
    "                self.value = value\n",
    "\n",
    "                \n",
    "    def __init__(self, max_depth, min_size):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        \n",
    "    \n",
    "    def make_tree(self, XY):\n",
    "        root = self.split(XY)\n",
    "        self.recursive_split(root, 1)\n",
    "        self.root = root\n",
    "        \n",
    "        \n",
    "    def split(self, XY):\n",
    "        unique_targets = list(set(row[-1] for row in XY))\n",
    "        feature_index, split_value, subtrees = None, None, None\n",
    "        min_gini_id = 100\n",
    "        \n",
    "        for i in range(XY.shape[1] - 1):\n",
    "            for row in XY:\n",
    "                s_trees = self.__get_subtrees(i, row[i], XY)\n",
    "                gini_id = self.__gini_index(s_trees, unique_targets)\n",
    "                if gini_id < min_gini_id:\n",
    "                    feature_index, split_value, subtrees = i, row[i], s_trees\n",
    "                    min_gini_id = gini_id\n",
    "                    \n",
    "        return Tree.Node(feature_index=feature_index, split_value=split_value, sons=subtrees)\n",
    "                \n",
    "                \n",
    "    def __get_subtrees(self, index, value, XY):\n",
    "        left, right = [], []\n",
    "        for row in XY:\n",
    "            if row[index] < value:\n",
    "                left.append(row)\n",
    "            else:\n",
    "                right.append(row)\n",
    "        return np.array(left), np.array(right)\n",
    "    \n",
    "    \n",
    "    def __gini_index(self, subtrees, unique_targets):\n",
    "        n_instances_in_subtrees = sum([len(subtree) for subtree in subtrees])\n",
    "        result = 0.\n",
    "        for subtree in subtrees:\n",
    "            n_instances_in_subtree = len(subtree)\n",
    "            if n_instances_in_subtree == 0:\n",
    "                continue\n",
    "            score = 0.\n",
    "            for target in unique_targets:\n",
    "                probability = [row[-1] for row in subtree].count(target) / n_instances_in_subtree\n",
    "                score += probability ** 2\n",
    "            result += (1. - score) * (n_instances_in_subtree / n_instances_in_subtrees)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def recursive_split(self, node, depth):\n",
    "        left, right = node.sons\n",
    "        node.sons = None\n",
    "        if not left.tolist() or not right.tolist():\n",
    "            node.left = node.right = self.make_leaf(left.tolist() + right.tolist())\n",
    "            return\n",
    "        if depth >= self.max_depth:\n",
    "            node.left, node.right = self.make_leaf(left), self.make_leaf(right)\n",
    "            return\n",
    "        \n",
    "        if len(left) <= self.min_size:\n",
    "            node.left = self.make_leaf(left)\n",
    "        else:\n",
    "            node.left = self.split(left)\n",
    "            self.recursive_split(node.left, depth + 1)\n",
    "        \n",
    "        if len(right) <= self.min_size:\n",
    "            node.right = self.make_leaf(right)\n",
    "        else:\n",
    "            node.right = self.split(right)\n",
    "            self.recursive_split(node.right, depth + 1)\n",
    "            \n",
    "    \n",
    "    def make_leaf(self, subtree):\n",
    "        targets = [row[-1] for row in subtree]\n",
    "        return Tree.Node(isLeaf=True, value=max(targets, key=targets.count))\n",
    "                \n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    \n",
    "    def __init__(self, max_depth=7, min_size=3):\n",
    "        self.tree = Tree(max_depth, min_size)\n",
    "        \n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.tree.make_tree(np.column_stack((X, Y)))\n",
    "        \n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.__predict_help(self.tree.root, x)\n",
    "    \n",
    "    \n",
    "    def __predict_help(self, node, row):\n",
    "        if row[node.feature_index] < node.split_value:\n",
    "            if not node.left.isLeaf:\n",
    "                return self.__predict_help(node.left, row)\n",
    "            else:\n",
    "                return node.left.value\n",
    "        else:\n",
    "            if not node.right.isLeaf:\n",
    "                return self.__predict_help(node.right, row)\n",
    "            else:\n",
    "                return node.right.value         \n",
    "    \n",
    "    def score(self, X, Y):\n",
    "        right_predict_number = 0\n",
    "        for i in range(Y.shape[0]):\n",
    "            if self.predict(X[i]) == Y[i]:\n",
    "                right_predict_number += 1\n",
    "                \n",
    "        return right_predict_number / Y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-choice",
   "metadata": {},
   "source": [
    "### Проверка точности и сравнение с реализацией sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "polyphonic-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат собственной реализации дерева решений на обучающей выборке: 85.77013291634088%\n",
      "Результат собственной реализации дерева решений на тестовой выборке: 71.25%\n"
     ]
    }
   ],
   "source": [
    "mdt = MyDecisionTreeClassifier()\n",
    "mdt.fit(features_train, target_train)\n",
    "print('Результат собственной реализации дерева решений на обучающей выборке: {}%'\n",
    "      .format(mdt.score(features_train, target_train) * 100))\n",
    "print('Результат собственной реализации дерева решений на тестовой выборке: {}%'\n",
    "      .format(mdt.score(features_test, target_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "quick-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат sklearn реализации дерева решений: 70.3125%\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=7)\n",
    "dt.fit(features_train, target_train)\n",
    "print('Результат sklearn реализации дерева решений: {}%'\n",
    "      .format(dt.score(features_test, target_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-resort",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "designed-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "class MyRandomForest:\n",
    "    \n",
    "    def __init__(self, max_depth=7, n_classifiers=30):\n",
    "        self.max_depth = max_depth\n",
    "        self.n_classifiers = n_classifiers\n",
    "        self.classifiers = []\n",
    "        self.features_indexes = []\n",
    "        self.x, self.y = None, None\n",
    "        \n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.x, self.y = X, Y\n",
    "        n_select_features = int(np.sqrt(self.x.shape[1]))\n",
    "        for _ in range(self.n_classifiers):\n",
    "            x, y = resample(self.x, self.y, n_samples=len(self.y))\n",
    "            \n",
    "            seq_features = [n for n in range(x.shape[1])]\n",
    "            new_x = []\n",
    "            for _ in range(n_select_features):\n",
    "                val = random.choice(seq_features)\n",
    "                new_x.append(val)\n",
    "                seq_features.remove(val)\n",
    "            self.features_indexes.append(new_x)\n",
    "            tree = MyDecisionTreeClassifier(max_depth=self.max_depth)\n",
    "            tree.fit(x[:,np.array(new_x)], y)\n",
    "            self.classifiers.append(tree)\n",
    "            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred = [classifier.predict(X[np.array(self.features_indexes[i])]) for i, classifier\n",
    "                in enumerate(self.classifiers)]\n",
    "        c = Counter(pred)\n",
    "        return c.most_common(1)[0][0]\n",
    "    \n",
    "    \n",
    "    def score(self, X, Y):\n",
    "        right_predict_number = 0\n",
    "        for i in range(Y.shape[0]):\n",
    "            if self.predict(X[i]) == Y[i]:\n",
    "                right_predict_number += 1\n",
    "                \n",
    "        return right_predict_number / Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adjustable-ranch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат собственной реализации random forest на обучающей выборке: 80.68803752931977%\n",
      "Результат собственной реализации random forest на тестовой выборке: 72.5%\n"
     ]
    }
   ],
   "source": [
    "mrf = MyRandomForest(max_depth=5, n_classifiers=15)\n",
    "mrf.fit(features_train, target_train)\n",
    "print('Результат собственной реализации random forest на обучающей выборке: {}%'\n",
    "      .format(mrf.score(features_train, target_train) * 100))\n",
    "print('Результат собственной реализации random forest на тестовой выборке: {}%'\n",
    "      .format(mrf.score(features_test, target_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "contrary-investing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат sklearn реализации random forest: 74.375%\n"
     ]
    }
   ],
   "source": [
    "dt = RandomForestClassifier(max_depth=5, n_estimators=15)\n",
    "dt.fit(features_train, target_train)\n",
    "print('Результат sklearn реализации random forest: {}%'\n",
    "      .format(dt.score(features_test, target_test) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
